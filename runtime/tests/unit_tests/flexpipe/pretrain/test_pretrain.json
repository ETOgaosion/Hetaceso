{
    "comment": "Only include flexpipe related configurations",
    "num_layers": 4,
    "num_stages": 4,
    "num_gpus": [
        2,
        2,
        4, 
        4
    ],
    "flex_recompute_activations": [
        true,
        false
    ],
    "resharding_stages": [
        false,
        false
    ],
    "num_ops_in_each_stage": [
        3,
        2,
        3,
        2
    ],
    "tensor_parallel_size_of_each_op": [
        [
            1,
            1,
            1
        ],
        [
            2,
            2
        ],
        [
            1,
            1,
            1
        ],
        [
            4,
            4
        ] 
    ],
    "data_parallel_size_of_each_op": [
        [
            2,
            2,
            2
        ],
        [
            1,
            1
        ],
        [
            4,
            4,
            4
        ],
        [
            1,
            1
        ] 
    ],
    "recompute_ops": [
        [
            0,
            0,
            0
        ],
        [
            0,
            0
        ],
        [
            0,
            0,
            0
        ],
        [
            0,
            0
        ] 
    ],
    "algo_of_each_op": [
        [
            0,
            0,
            0
        ],
        [
            0,
            0
        ],
        [
            0,
            0,
            0
        ],
        [
            0,
            0
        ] 
    ]
}