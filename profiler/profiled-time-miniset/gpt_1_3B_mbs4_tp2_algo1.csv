op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,5819.124,2138.579,0.031,32.000,108.000,48.070,95.930,248.000
enc-1st-layernorm,117.952,395.906,32.000,64.000,0.000,32.062,0.000,256.000
enc-attention-qkv,15871.578,2799.731,48.000,128.000,12.000,96.000,96.000,370.000
enc-attention-score,1036.656,1965.839,96.000,576.000,0.000,512.000,512.000,1072.000
enc-attention-softmax,1168.805,1473.022,576.000,576.000,0.000,512.000,0.000,1536.000
enc-attention-dropout,1894.999,1617.843,576.000,576.000,0.000,768.000,0.000,2048.000
enc-attention-context,1325.029,1754.320,576.000,64.000,0.000,16.000,16.000,560.000
enc-attention-dense,5261.058,768.167,64.000,80.004,4.000,32.000,0.000,112.000
enc-post-attention-dropout,363.004,192.124,80.004,48.000,0.000,48.000,32.000,208.000
enc-2nd-layernorm,110.847,395.083,48.000,80.000,0.000,32.062,0.000,256.000
enc-MLP-GEMM-1,1620.436,8216.125,80.000,112.008,16.000,64.000,0.000,240.000
enc-MLP-gelu,182.086,341.403,112.008,112.000,0.000,64.000,0.000,336.000
enc-MLP-GEMM-2,6431.228,2919.388,112.000,80.004,16.000,32.000,0.000,176.000
enc-post-MLP-dropout,341.213,190.872,80.004,48.000,0.000,48.000,32.000,208.000
final-layernorm,213.706,554.013,48.000,48.000,0.000,64.062,0.000,128.000
gpt-post-process,19444.734,25706.470,48.000,16.000,100.000,800.102,399.898,0.000
