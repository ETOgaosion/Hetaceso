op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,7583.481,1771.909,0.031,32.000,58.000,48.070,95.930,192.000
enc-1st-layernorm,110.471,393.844,32.000,64.000,0.000,32.062,0.000,256.000
enc-attention-qkv,670.451,7838.392,64.000,56.000,6.000,24.000,16.000,190.000
enc-attention-score,525.415,1061.577,56.000,296.000,0.000,256.000,256.000,552.000
enc-attention-softmax,582.564,748.575,296.000,296.000,0.000,256.000,0.000,768.000
enc-attention-dropout,939.012,813.168,296.000,296.000,0.000,384.000,0.000,1024.000
enc-attention-context,604.999,923.717,296.000,40.000,0.000,8.000,12.000,272.000
enc-attention-dense,6502.110,428.516,40.000,64.004,2.000,32.000,0.000,116.000
enc-post-attention-dropout,341.159,191.760,64.004,32.000,0.000,48.000,32.000,208.000
enc-2nd-layernorm,110.865,385.427,32.000,64.000,0.000,32.062,0.000,256.000
enc-MLP-GEMM-1,822.961,8077.353,64.000,64.004,8.000,32.000,0.000,128.000
enc-MLP-gelu,94.330,185.716,64.004,64.000,0.000,32.000,0.000,208.000
enc-MLP-GEMM-2,7027.870,1518.047,64.000,64.004,8.000,32.000,0.000,128.000
enc-post-MLP-dropout,341.606,191.069,64.004,32.000,0.000,48.000,32.000,208.000
final-layernorm,214.314,499.809,32.000,32.000,0.000,64.062,0.000,128.000
gpt-post-process,10097.182,16785.330,32.000,0.000,50.000,400.102,199.898,0.000
