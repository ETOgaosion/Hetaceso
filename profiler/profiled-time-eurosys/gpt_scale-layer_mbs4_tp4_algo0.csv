op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,495.826,760.659,0.031,8.000,14.500,12.070,7.930,48.000
enc-1st-layernorm,45.593,120.114,8.000,16.000,0.000,8.062,0.000,72.000
enc-attention-qkv,205.116,665.344,16.000,14.000,0.375,6.000,0.000,64.000
enc-attention-score,132.108,271.060,14.000,74.000,0.000,64.000,64.000,128.000
enc-attention-softmax,158.617,211.686,74.000,74.000,0.000,64.000,0.000,192.000
enc-attention-dropout,242.120,209.905,74.000,74.000,0.000,96.000,0.000,256.000
enc-attention-context,130.256,236.812,74.000,10.000,0.000,2.000,0.000,64.000
enc-attention-dense,427.419,133.117,10.000,16.001,0.125,8.000,0.000,16.000
enc-post-attention-dropout,98.655,77.816,16.001,8.000,0.000,12.000,8.000,68.000
enc-2nd-layernorm,41.323,121.437,8.000,16.000,0.000,8.062,0.000,72.000
enc-MLP-GEMM-1,89.946,504.659,16.000,16.001,0.500,8.000,0.000,36.000
enc-MLP-gelu,34.132,97.923,16.001,16.000,0.000,8.000,0.000,68.000
enc-MLP-GEMM-2,428.655,154.291,16.000,16.001,0.500,8.000,0.000,36.000
enc-post-MLP-dropout,105.484,79.281,16.001,8.000,0.000,12.000,8.000,68.000
final-layernorm,68.135,1606.892,8.000,8.000,0.000,16.062,3.938,36.000
gpt-post-process,6624.564,4637.135,8.000,0.000,12.500,400.102,199.898,0.000
