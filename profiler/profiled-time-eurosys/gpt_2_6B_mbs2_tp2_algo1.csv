op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1178.982,1748.650,0.016,20.000,135.000,30.035,49.965,206.000
enc-1st-layernorm,81.015,288.910,20.000,40.000,0.000,20.031,0.000,160.000
enc-attention-qkv,3160.264,1906.476,30.000,80.000,18.750,60.000,60.000,264.000
enc-attention-score,697.094,1147.346,60.000,296.000,0.000,256.000,256.000,542.000
enc-attention-softmax,612.339,840.507,296.000,296.000,0.000,256.000,0.000,768.000
enc-attention-dropout,957.009,827.960,296.000,296.000,0.000,384.000,0.000,1024.000
enc-attention-context,652.668,1207.684,296.000,40.000,0.000,10.000,10.000,286.000
enc-attention-dense,1034.026,586.771,40.000,50.005,6.250,20.000,0.000,80.000
enc-post-attention-dropout,230.420,132.601,50.005,30.000,0.000,30.000,20.000,160.000
enc-2nd-layernorm,81.331,287.713,30.000,50.000,0.000,20.031,0.000,160.000
enc-MLP-GEMM-1,1309.124,2871.990,50.000,70.010,25.000,40.000,0.000,166.000
enc-MLP-gelu,115.162,236.925,70.010,70.000,0.000,40.000,0.000,240.000
enc-MLP-GEMM-2,1935.436,2228.907,70.000,50.005,25.000,20.000,0.000,126.000
enc-post-MLP-dropout,231.982,123.580,50.005,30.000,0.000,30.000,20.000,160.000
final-layernorm,157.332,1596.553,30.000,30.000,0.000,40.031,0.000,80.000
gpt-post-process,10858.233,12446.553,30.000,10.000,125.000,400.051,199.949,0.000
