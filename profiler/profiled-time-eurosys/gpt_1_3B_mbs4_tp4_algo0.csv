op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1611.221,1780.130,0.031,32.000,58.000,48.070,95.930,192.000
enc-1st-layernorm,112.971,444.586,32.000,64.000,0.000,32.062,0.000,256.000
enc-attention-qkv,707.715,2212.372,64.000,56.000,6.000,24.000,16.000,190.000
enc-attention-score,527.982,1138.344,56.000,296.000,0.000,256.000,256.000,552.000
enc-attention-softmax,615.385,846.959,296.000,296.000,0.000,256.000,0.000,768.000
enc-attention-dropout,970.329,827.415,296.000,296.000,0.000,384.000,0.000,1024.000
enc-attention-context,665.797,906.442,296.000,40.000,0.000,8.000,12.000,272.000
enc-attention-dense,1054.196,394.989,40.000,64.004,2.000,32.000,0.000,116.000
enc-post-attention-dropout,361.358,219.227,64.004,32.000,0.000,48.000,32.000,208.000
enc-2nd-layernorm,113.257,440.034,32.000,64.000,0.000,32.062,0.000,256.000
enc-MLP-GEMM-1,853.758,2381.915,64.000,64.004,8.000,32.000,0.000,128.000
enc-MLP-gelu,93.094,218.600,64.004,64.000,0.000,32.000,0.000,208.000
enc-MLP-GEMM-2,1672.384,1428.486,64.000,64.004,8.000,32.000,0.000,128.000
enc-post-MLP-dropout,362.419,192.925,64.004,32.000,0.000,48.000,32.000,208.000
final-layernorm,222.180,1615.649,32.000,32.000,0.000,64.062,0.000,128.000
gpt-post-process,9634.145,10911.083,32.000,0.000,50.000,400.102,199.898,0.000
