op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,573.883,776.258,0.008,10.000,41.250,15.018,0.000,82.000
enc-1st-layernorm,47.450,151.469,10.000,20.000,0.000,10.016,0.000,80.000
enc-attention-qkv,1004.238,499.092,11.250,40.000,4.688,30.000,30.000,174.000
enc-attention-score,80.644,188.730,22.500,52.000,0.000,32.000,32.000,64.000
enc-attention-softmax,82.773,112.771,52.000,52.000,0.000,32.000,0.000,96.000
enc-attention-dropout,123.019,107.235,52.000,52.000,0.000,48.000,0.000,128.000
enc-attention-context,98.221,168.009,52.000,20.000,0.000,1.250,0.000,32.000
enc-attention-dense,537.789,145.035,20.000,28.755,1.562,10.000,0.000,30.000
enc-post-attention-dropout,120.797,84.307,28.755,18.750,0.000,15.000,15.000,80.000
enc-2nd-layernorm,47.181,152.087,18.750,28.750,0.000,10.016,0.000,80.000
enc-MLP-GEMM-1,162.715,783.380,28.750,23.752,6.250,5.000,15.000,20.000
enc-MLP-gelu,34.071,97.272,23.752,23.750,0.000,5.000,0.000,40.000
enc-MLP-GEMM-2,593.172,293.735,23.750,28.755,6.250,10.000,0.000,50.000
enc-post-MLP-dropout,121.175,78.086,28.755,18.750,0.000,15.000,15.000,80.000
final-layernorm,47.429,1011.142,18.750,18.750,0.000,10.016,0.000,40.000
gpt-post-process,1791.596,2132.635,18.750,8.750,31.250,50.025,25.975,0.000
