op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1964.166,2374.654,0.016,40.000,145.000,60.035,119.965,306.000
enc-1st-layernorm,208.594,653.375,40.000,80.000,0.000,40.031,0.000,320.000
enc-attention-qkv,1982.155,4611.528,80.000,70.000,37.500,30.000,30.000,250.000
enc-attention-score,511.565,721.153,70.000,210.000,0.000,160.000,160.000,350.000
enc-attention-softmax,386.406,529.751,210.000,210.000,0.000,160.000,0.000,480.000
enc-attention-dropout,602.467,518.318,210.000,210.000,0.000,240.000,0.000,640.000
enc-attention-context,406.330,840.466,210.000,50.000,0.000,10.000,10.000,190.000
enc-attention-dense,1685.230,1114.630,50.000,80.010,12.500,40.000,0.000,144.000
enc-post-attention-dropout,449.456,275.717,80.010,40.000,0.000,60.000,40.000,240.000
enc-2nd-layernorm,209.637,652.220,40.000,80.000,0.000,40.031,0.000,320.000
enc-MLP-GEMM-1,2513.810,5187.902,80.000,80.010,50.000,40.000,0.000,210.000
enc-MLP-gelu,115.975,232.326,80.010,80.000,0.000,40.000,0.000,240.000
enc-MLP-GEMM-2,3454.003,4169.774,80.000,80.010,50.000,40.000,0.000,210.000
enc-post-MLP-dropout,451.578,248.773,80.010,40.000,0.000,60.000,40.000,240.000
final-layernorm,345.643,1595.310,40.000,40.000,0.000,80.031,0.000,160.000
gpt-post-process,8315.307,11710.669,40.000,0.000,125.000,200.051,99.949,0.000
