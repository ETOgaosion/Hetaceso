op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,908.333,1181.139,0.008,20.000,82.500,30.018,19.982,164.000
enc-1st-layernorm,115.787,334.195,20.000,40.000,0.000,20.016,0.000,160.000
enc-attention-qkv,1965.268,1201.261,22.500,80.000,18.750,60.000,60.000,264.000
enc-attention-score,123.492,214.033,45.000,80.000,0.000,40.000,40.000,80.000
enc-attention-softmax,1083.350,1759.349,80.000,80.000,0.000,120.000,80.000,280.000
enc-attention-dropout,153.484,133.396,80.000,80.000,0.000,60.000,0.000,160.000
enc-attention-context,108.703,212.367,80.000,40.000,0.000,2.500,0.000,40.000
enc-attention-dense,679.770,345.793,40.000,57.510,6.250,20.000,0.000,60.000
enc-post-attention-dropout,229.912,134.003,57.510,37.500,0.000,30.000,20.000,160.000
enc-2nd-layernorm,115.771,332.358,37.500,57.500,0.000,20.016,0.000,160.000
enc-MLP-GEMM-1,610.648,1878.254,57.500,47.505,25.000,10.000,0.000,76.000
enc-MLP-gelu,35.090,94.845,47.505,47.500,0.000,10.000,0.000,80.000
enc-MLP-GEMM-2,1125.194,1043.293,47.500,57.510,25.000,20.000,0.000,96.000
enc-post-MLP-dropout,231.589,123.610,57.510,37.500,0.000,30.000,20.000,160.000
final-layernorm,118.426,1002.427,37.500,37.500,0.000,20.016,0.000,80.000
gpt-post-process,2379.066,3493.383,37.500,17.500,62.500,50.025,25.975,0.000
