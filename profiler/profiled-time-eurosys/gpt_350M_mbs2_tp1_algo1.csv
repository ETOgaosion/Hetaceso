op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,214.508,1101.629,0.016,8.000,104.000,12.000,8.000,132.000
enc-1st-layernorm,42.524,116.478,8.000,16.000,0.000,8.031,0.000,72.000
enc-attention-qkv,501.078,760.713,16.000,32.000,6.000,24.000,24.000,158.000
enc-attention-score,524.065,1161.785,32.000,272.000,0.000,256.000,256.000,552.000
enc-attention-softmax,615.491,836.709,272.000,272.000,0.000,256.000,0.000,768.000
enc-attention-dropout,979.257,828.120,272.000,272.000,0.000,384.000,0.000,1024.000
enc-attention-context,678.209,902.812,272.000,16.000,0.000,8.000,12.000,272.000
enc-attention-dense,129.340,227.979,16.000,16.002,2.000,8.000,12.000,36.000
enc-post-attention-dropout,99.626,77.037,16.002,8.000,0.000,12.000,8.000,68.000
enc-2nd-layernorm,42.474,114.474,8.000,16.000,0.000,8.031,0.000,72.000
enc-MLP-GEMM-1,445.368,812.134,16.000,40.008,8.000,32.000,0.000,116.000
enc-MLP-gelu,92.998,989.739,40.008,40.000,0.000,32.000,0.000,208.000
enc-MLP-GEMM-2,454.518,849.446,40.000,16.002,8.000,8.000,0.000,68.000
enc-post-MLP-dropout,99.657,77.043,16.002,8.000,0.000,12.000,8.000,68.000
final-layernorm,65.503,1573.142,8.000,8.000,0.000,16.031,3.969,36.000
gpt-post-process,14785.830,11796.010,8.000,0.000,100.000,800.051,399.949,0.000
