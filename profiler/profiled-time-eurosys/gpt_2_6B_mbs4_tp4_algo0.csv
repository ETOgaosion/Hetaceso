op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1983.410,2080.218,0.031,40.000,72.500,60.070,119.930,240.000
enc-1st-layernorm,145.332,555.023,40.000,80.000,0.000,40.062,0.000,320.000
enc-attention-qkv,1082.805,2973.731,80.000,70.000,9.375,30.000,0.000,232.000
enc-attention-score,689.573,1139.205,70.000,306.000,0.000,256.000,256.000,542.000
enc-attention-softmax,610.921,835.962,306.000,306.000,0.000,256.000,0.000,768.000
enc-attention-dropout,965.812,829.176,306.000,306.000,0.000,384.000,0.000,1024.000
enc-attention-context,641.710,1200.490,306.000,50.000,0.000,10.000,10.000,286.000
enc-attention-dense,1379.911,591.291,50.000,80.005,3.125,40.000,0.000,130.000
enc-post-attention-dropout,447.414,246.578,80.005,40.000,0.000,60.000,40.000,240.000
enc-2nd-layernorm,145.332,549.136,40.000,80.000,0.000,40.062,0.000,320.000
enc-MLP-GEMM-1,1376.487,3237.292,80.000,80.005,12.500,40.000,0.000,160.000
enc-MLP-gelu,115.758,234.003,80.005,80.000,0.000,40.000,0.000,240.000
enc-MLP-GEMM-2,2372.361,2175.782,80.000,80.005,12.500,40.000,0.000,160.000
enc-post-MLP-dropout,450.404,239.743,80.005,40.000,0.000,60.000,40.000,240.000
final-layernorm,285.780,1638.243,40.000,40.000,0.000,80.062,0.000,160.000
gpt-post-process,10876.123,12989.255,40.000,0.000,62.500,400.102,199.898,0.000
