op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,865.910,1186.562,0.062,16.000,14.500,24.141,43.859,64.000
enc-1st-layernorm,69.572,222.880,16.000,32.000,0.000,16.125,0.000,128.000
enc-attention-qkv,204.381,906.668,32.000,28.000,0.375,12.000,20.000,96.000
enc-attention-score,261.687,587.755,28.000,148.000,0.000,128.000,128.000,256.000
enc-attention-softmax,308.717,417.246,148.000,148.000,0.000,128.000,0.000,384.000
enc-attention-dropout,482.650,416.137,148.000,148.000,0.000,192.000,0.000,512.000
enc-attention-context,349.468,497.437,148.000,20.000,0.000,4.000,0.000,148.000
enc-attention-dense,597.270,135.229,20.000,32.001,0.125,16.000,0.000,68.000
enc-post-attention-dropout,185.512,104.277,32.001,16.000,0.000,24.000,28.000,128.000
enc-2nd-layernorm,69.540,221.323,16.000,32.000,0.000,16.125,0.000,128.000
enc-MLP-GEMM-1,123.008,803.499,32.000,32.001,0.500,16.000,0.000,64.000
enc-MLP-gelu,48.838,125.102,32.001,32.000,0.000,16.000,0.000,128.000
enc-MLP-GEMM-2,632.739,240.650,32.000,32.001,0.500,16.000,0.000,64.000
enc-post-MLP-dropout,186.359,102.632,32.001,16.000,0.000,24.000,28.000,128.000
final-layernorm,128.865,1597.018,16.000,16.000,0.000,32.125,0.000,64.000
gpt-post-process,12784.830,8778.973,16.000,0.000,12.500,800.203,399.797,0.000
