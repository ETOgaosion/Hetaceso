op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,396.777,433.722,0.008,2.000,14.500,3.018,0.000,0.000
enc-1st-layernorm,41.050,94.820,2.000,4.000,0.000,2.016,0.000,0.000
enc-attention-qkv,563.698,234.064,2.500,8.000,0.375,6.000,14.000,44.000
enc-attention-score,69.791,134.037,5.000,20.000,0.000,16.000,16.000,34.000
enc-attention-softmax,447.574,719.446,20.000,20.000,0.000,48.000,32.000,112.000
enc-attention-dropout,63.206,61.300,20.000,20.000,0.000,24.000,12.000,64.000
enc-attention-context,79.801,115.448,20.000,4.000,0.000,0.500,0.000,18.000
enc-attention-dense,341.016,147.763,4.000,5.501,0.125,2.000,18.000,0.000
enc-post-attention-dropout,76.538,77.657,5.501,3.500,0.000,3.000,0.000,20.000
enc-2nd-layernorm,41.223,91.449,3.500,5.500,0.000,2.016,0.000,0.000
enc-MLP-GEMM-1,87.656,370.014,5.500,5.501,0.500,2.000,0.000,0.000
enc-MLP-gelu,34.527,90.816,5.501,5.500,0.000,2.000,0.000,0.000
enc-MLP-GEMM-2,334.409,131.233,5.500,5.501,0.500,2.000,0.000,0.000
enc-post-MLP-dropout,77.068,78.740,5.501,3.500,0.000,3.000,0.000,20.000
final-layernorm,51.613,960.184,3.500,3.500,0.000,2.016,0.000,0.000
gpt-post-process,1979.060,1503.505,3.500,1.500,12.500,100.025,49.975,0.000
