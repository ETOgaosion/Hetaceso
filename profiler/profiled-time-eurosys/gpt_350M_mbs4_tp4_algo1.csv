op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,867.872,1148.387,0.031,16.000,29.000,24.070,39.930,96.000
enc-1st-layernorm,55.606,201.296,16.000,32.000,0.000,16.062,0.000,128.000
enc-attention-qkv,1673.536,672.876,20.000,64.000,1.500,48.000,48.000,226.000
enc-attention-score,262.506,611.242,40.000,160.000,0.000,128.000,128.000,256.000
enc-attention-softmax,312.699,409.617,160.000,160.000,0.000,128.000,0.000,384.000
enc-attention-dropout,482.203,415.940,160.000,160.000,0.000,192.000,0.000,512.000
enc-attention-context,361.352,495.931,160.000,32.000,0.000,4.000,0.000,148.000
enc-attention-dense,629.793,165.932,32.000,44.002,0.500,16.000,0.000,68.000
enc-post-attention-dropout,185.633,107.468,44.002,28.000,0.000,24.000,28.000,128.000
enc-2nd-layernorm,55.525,202.279,28.000,44.000,0.000,16.062,0.000,128.000
enc-MLP-GEMM-1,233.998,951.284,44.000,44.002,2.000,16.000,0.000,64.000
enc-MLP-gelu,48.757,118.418,44.002,44.000,0.000,16.000,0.000,128.000
enc-MLP-GEMM-2,724.405,396.867,44.000,44.002,2.000,16.000,0.000,64.000
enc-post-MLP-dropout,186.659,100.015,44.002,28.000,0.000,24.000,28.000,128.000
final-layernorm,114.123,1623.411,28.000,28.000,0.000,32.062,0.000,64.000
gpt-post-process,7675.111,6544.020,28.000,12.000,25.000,400.102,199.898,0.000
