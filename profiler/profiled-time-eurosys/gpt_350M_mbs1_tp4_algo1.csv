op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,415.360,581.851,0.008,4.000,29.000,6.018,13.982,46.000
enc-1st-layernorm,43.012,93.845,4.000,8.000,0.000,4.016,0.000,20.000
enc-attention-qkv,665.723,237.986,5.000,16.000,1.500,12.000,0.000,82.000
enc-attention-score,66.442,159.216,10.000,40.000,0.000,32.000,32.000,68.000
enc-attention-softmax,83.551,109.226,40.000,40.000,0.000,32.000,0.000,96.000
enc-attention-dropout,124.061,107.275,40.000,40.000,0.000,48.000,0.000,128.000
enc-attention-context,84.193,138.223,40.000,8.000,0.000,1.000,1.000,52.000
enc-attention-dense,376.558,132.301,8.000,11.002,0.500,4.000,16.000,2.000
enc-post-attention-dropout,69.857,75.421,11.002,7.000,0.000,6.000,0.000,36.000
enc-2nd-layernorm,42.696,96.196,7.000,11.000,0.000,4.016,0.000,20.000
enc-MLP-GEMM-1,88.379,428.692,11.000,11.002,2.000,4.000,0.000,20.000
enc-MLP-gelu,33.771,912.702,11.002,11.000,0.000,4.000,0.000,20.000
enc-MLP-GEMM-2,374.976,129.021,11.000,11.002,2.000,4.000,0.000,20.000
enc-post-MLP-dropout,77.639,79.396,11.002,7.000,0.000,6.000,0.000,36.000
final-layernorm,45.130,946.628,7.000,7.000,0.000,4.016,0.000,20.000
gpt-post-process,2238.612,2013.532,7.000,3.000,25.000,100.025,49.975,0.000
