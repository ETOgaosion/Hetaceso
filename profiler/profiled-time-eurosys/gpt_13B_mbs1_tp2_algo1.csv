op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1093.640,2178.246,0.008,20.000,270.000,30.018,19.982,330.000
enc-1st-layernorm,115.727,332.443,20.000,40.000,0.000,20.016,0.000,160.000
enc-attention-qkv,4016.083,3563.614,30.000,80.000,75.000,60.000,60.000,264.000
enc-attention-score,523.336,739.367,60.000,200.000,0.000,160.000,160.000,350.000
enc-attention-softmax,384.525,525.931,200.000,200.000,0.000,160.000,0.000,480.000
enc-attention-dropout,602.189,519.072,200.000,200.000,0.000,240.000,0.000,640.000
enc-attention-context,411.000,845.213,200.000,40.000,0.000,10.000,10.000,190.000
enc-attention-dense,1330.987,1043.135,40.000,50.010,25.000,20.000,0.000,96.000
enc-post-attention-dropout,232.699,123.862,50.010,30.000,0.000,30.000,20.000,160.000
enc-2nd-layernorm,117.656,331.529,30.000,50.000,0.000,20.016,0.000,160.000
enc-MLP-GEMM-1,2529.459,5078.585,50.000,70.020,100.000,40.000,0.000,240.000
enc-MLP-gelu,117.018,229.416,70.020,70.000,0.000,40.000,0.000,240.000
enc-MLP-GEMM-2,3195.624,4423.201,70.000,50.010,100.000,20.000,0.000,200.000
enc-post-MLP-dropout,232.750,123.581,50.010,30.000,0.000,30.000,20.000,160.000
final-layernorm,119.566,944.875,30.000,30.000,0.000,20.016,0.000,80.000
gpt-post-process,8228.441,11943.256,30.000,10.000,250.000,200.025,99.975,250.000
