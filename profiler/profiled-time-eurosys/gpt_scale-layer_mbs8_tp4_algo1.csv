op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,865.910,1186.562,0.062,16.000,14.500,24.141,43.859,64.000
enc-1st-layernorm,69.572,222.880,16.000,32.000,0.000,16.125,0.000,128.000
enc-attention-qkv,1570.883,556.867,20.000,64.000,0.375,48.000,48.000,210.000
enc-attention-score,261.687,587.755,40.000,160.000,0.000,128.000,128.000,256.000
enc-attention-softmax,308.717,417.246,160.000,160.000,0.000,128.000,0.000,384.000
enc-attention-dropout,482.650,416.137,160.000,160.000,0.000,192.000,0.000,512.000
enc-attention-context,349.468,497.437,160.000,32.000,0.000,4.000,0.000,148.000
enc-attention-dense,600.002,134.408,32.000,44.001,0.125,16.000,0.000,68.000
enc-post-attention-dropout,185.512,104.277,44.001,28.000,0.000,24.000,28.000,128.000
enc-2nd-layernorm,69.540,221.323,28.000,44.000,0.000,16.125,0.000,128.000
enc-MLP-GEMM-1,122.901,773.718,44.000,44.001,0.500,16.000,0.000,64.000
enc-MLP-gelu,48.838,125.102,44.001,44.000,0.000,16.000,0.000,128.000
enc-MLP-GEMM-2,638.654,241.030,44.000,44.001,0.500,16.000,0.000,64.000
enc-post-MLP-dropout,186.359,102.632,44.001,28.000,0.000,24.000,28.000,128.000
final-layernorm,128.865,1597.018,28.000,28.000,0.000,32.125,0.000,64.000
gpt-post-process,12784.830,8778.973,28.000,12.000,12.500,800.203,399.797,0.000
