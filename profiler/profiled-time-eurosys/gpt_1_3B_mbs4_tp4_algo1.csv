op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1611.221,1780.130,0.031,32.000,58.000,48.070,95.930,192.000
enc-1st-layernorm,112.971,444.586,32.000,64.000,0.000,32.062,0.000,256.000
enc-attention-qkv,3406.353,1629.583,40.000,128.000,6.000,96.000,96.000,370.000
enc-attention-score,527.982,1138.344,80.000,320.000,0.000,256.000,256.000,552.000
enc-attention-softmax,615.385,846.959,320.000,320.000,0.000,256.000,0.000,768.000
enc-attention-dropout,970.329,827.415,320.000,320.000,0.000,384.000,0.000,1024.000
enc-attention-context,665.797,906.442,320.000,64.000,0.000,8.000,12.000,272.000
enc-attention-dense,1066.247,395.174,64.000,88.004,2.000,32.000,0.000,96.000
enc-post-attention-dropout,361.358,219.227,88.004,56.000,0.000,48.000,32.000,208.000
enc-2nd-layernorm,113.257,440.034,56.000,88.000,0.000,32.062,0.000,256.000
enc-MLP-GEMM-1,863.363,2393.428,88.000,88.004,8.000,32.000,0.000,128.000
enc-MLP-gelu,93.094,218.600,88.004,88.000,0.000,32.000,0.000,208.000
enc-MLP-GEMM-2,1667.147,1429.162,88.000,88.004,8.000,32.000,0.000,128.000
enc-post-MLP-dropout,362.419,192.925,88.004,56.000,0.000,48.000,32.000,208.000
final-layernorm,222.180,1615.649,56.000,56.000,0.000,64.062,0.000,128.000
gpt-post-process,9634.145,10911.083,56.000,24.000,50.000,400.102,199.898,0.000
