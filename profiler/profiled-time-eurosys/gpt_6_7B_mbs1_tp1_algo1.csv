op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,349.269,2649.674,0.008,16.000,416.000,24.000,0.000,432.000
enc-1st-layernorm,92.446,260.661,16.000,32.000,0.000,16.016,0.000,128.000
enc-attention-qkv,2786.998,4554.256,32.000,64.000,96.000,48.000,0.000,292.000
enc-attention-score,781.593,1194.453,64.000,288.000,0.000,256.000,256.000,560.000
enc-attention-softmax,611.699,840.508,288.000,288.000,0.000,256.000,0.000,768.000
enc-attention-dropout,962.110,827.546,288.000,288.000,0.000,384.000,0.000,1024.000
enc-attention-context,652.624,1285.262,288.000,32.000,0.000,16.000,16.000,304.000
enc-attention-dense,940.732,1641.800,32.000,32.008,32.000,16.000,0.000,96.000
enc-post-attention-dropout,187.619,101.532,32.008,16.000,0.000,24.000,28.000,128.000
enc-2nd-layernorm,87.907,263.493,16.000,32.000,0.000,16.016,0.000,128.000
enc-MLP-GEMM-1,3229.859,5581.206,32.000,80.031,128.000,64.000,0.000,336.000
enc-MLP-gelu,184.836,352.222,80.031,80.000,0.000,64.000,0.000,336.000
enc-MLP-GEMM-2,3296.801,5613.786,80.000,32.008,128.000,16.000,0.000,240.000
enc-post-MLP-dropout,187.926,100.477,32.008,16.000,0.000,24.000,28.000,128.000
final-layernorm,88.454,949.209,16.000,16.000,0.000,16.016,0.000,64.000
gpt-post-process,13627.272,18714.885,16.000,0.000,400.000,400.025,199.975,0.000
