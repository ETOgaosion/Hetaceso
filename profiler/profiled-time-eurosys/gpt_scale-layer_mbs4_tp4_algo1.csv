op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,495.826,760.659,0.031,8.000,14.500,12.070,7.930,48.000
enc-1st-layernorm,45.593,120.114,8.000,16.000,0.000,8.062,0.000,72.000
enc-attention-qkv,918.568,305.402,10.000,32.000,0.375,24.000,24.000,142.000
enc-attention-score,132.108,271.060,20.000,80.000,0.000,64.000,64.000,128.000
enc-attention-softmax,158.617,211.686,80.000,80.000,0.000,64.000,0.000,192.000
enc-attention-dropout,242.120,209.905,80.000,80.000,0.000,96.000,0.000,256.000
enc-attention-context,130.256,236.812,80.000,16.000,0.000,2.000,0.000,64.000
enc-attention-dense,435.280,139.707,16.000,22.001,0.125,8.000,0.000,16.000
enc-post-attention-dropout,98.655,77.816,22.001,14.000,0.000,12.000,8.000,68.000
enc-2nd-layernorm,41.323,121.437,14.000,22.000,0.000,8.062,0.000,72.000
enc-MLP-GEMM-1,90.035,516.317,22.000,22.001,0.500,8.000,0.000,36.000
enc-MLP-gelu,34.132,97.923,22.001,22.000,0.000,8.000,0.000,68.000
enc-MLP-GEMM-2,440.421,154.256,22.000,22.001,0.500,8.000,0.000,36.000
enc-post-MLP-dropout,105.484,79.281,22.001,14.000,0.000,12.000,8.000,68.000
final-layernorm,68.135,1606.892,14.000,14.000,0.000,16.062,3.938,36.000
gpt-post-process,6624.564,4637.135,14.000,6.000,12.500,400.102,199.898,0.000
