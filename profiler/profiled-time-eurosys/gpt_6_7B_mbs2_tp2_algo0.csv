op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1795.242,2499.439,0.016,32.000,216.000,48.035,79.965,328.000
enc-1st-layernorm,156.037,493.815,32.000,64.000,0.000,32.031,0.000,256.000
enc-attention-qkv,2646.258,5449.272,64.000,80.000,48.000,48.000,32.000,306.000
enc-attention-score,784.720,1190.698,80.000,304.000,0.000,256.000,256.000,560.000
enc-attention-softmax,612.701,806.288,304.000,304.000,0.000,256.000,0.000,768.000
enc-attention-dropout,959.429,826.931,304.000,304.000,0.000,384.000,0.000,1024.000
enc-attention-context,673.569,1284.350,304.000,48.000,0.000,16.000,16.000,304.000
enc-attention-dense,1873.882,1513.282,48.000,64.008,16.000,32.000,0.000,128.000
enc-post-attention-dropout,362.250,201.424,64.008,32.000,0.000,48.000,32.000,208.000
enc-2nd-layernorm,155.841,487.310,32.000,64.000,0.000,32.031,0.000,256.000
enc-MLP-GEMM-1,3223.516,6493.648,64.000,96.016,64.000,64.000,0.000,288.000
enc-MLP-gelu,183.264,357.971,96.016,96.000,0.000,64.000,0.000,336.000
enc-MLP-GEMM-2,4210.351,5689.259,96.000,64.008,64.000,32.000,0.000,224.000
enc-post-MLP-dropout,363.444,193.471,64.008,32.000,0.000,48.000,32.000,208.000
final-layernorm,266.088,1573.696,32.000,32.000,0.000,64.031,0.000,128.000
gpt-post-process,13599.057,18476.826,32.000,0.000,200.000,400.051,199.949,0.000
