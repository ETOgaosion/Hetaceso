op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1617.144,1977.584,0.016,32.000,116.000,48.035,95.965,228.000
enc-1st-layernorm,154.002,485.998,32.000,64.000,0.000,32.031,0.000,256.000
enc-attention-qkv,4025.314,2551.044,40.000,128.000,24.000,96.000,96.000,372.000
enc-attention-score,372.586,631.468,80.000,192.000,0.000,128.000,128.000,296.000
enc-attention-softmax,310.287,403.181,192.000,192.000,0.000,128.000,0.000,384.000
enc-attention-dropout,481.279,416.130,192.000,192.000,0.000,192.000,0.000,512.000
enc-attention-context,358.772,654.457,192.000,64.000,0.000,8.000,12.000,144.000
enc-attention-dense,1259.327,748.845,64.000,88.008,8.000,32.000,0.000,96.000
enc-post-attention-dropout,362.728,203.879,88.008,56.000,0.000,48.000,32.000,208.000
enc-2nd-layernorm,155.395,490.187,56.000,88.000,0.000,32.031,0.000,256.000
enc-MLP-GEMM-1,1671.535,3840.497,88.000,88.008,32.000,32.000,0.000,160.000
enc-MLP-gelu,93.131,201.168,88.008,88.000,0.000,32.000,0.000,208.000
enc-MLP-GEMM-2,2459.347,2913.127,88.000,88.008,32.000,32.000,0.000,160.000
enc-post-MLP-dropout,363.427,193.216,88.008,56.000,0.000,48.000,32.000,208.000
final-layernorm,266.875,1576.226,56.000,56.000,0.000,64.031,0.000,128.000
gpt-post-process,7011.102,9790.337,56.000,24.000,100.000,200.051,99.949,0.000
