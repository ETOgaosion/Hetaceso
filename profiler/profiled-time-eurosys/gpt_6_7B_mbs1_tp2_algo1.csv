op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,890.156,1822.786,0.008,16.000,216.000,24.018,39.982,264.000
enc-1st-layernorm,88.245,264.113,16.000,32.000,0.000,16.016,0.000,128.000
enc-attention-qkv,2985.927,2417.712,24.000,64.000,48.000,48.000,48.000,196.000
enc-attention-score,375.658,675.626,48.000,160.000,0.000,128.000,128.000,296.000
enc-attention-softmax,308.720,404.807,160.000,160.000,0.000,128.000,0.000,384.000
enc-attention-dropout,482.861,415.908,160.000,160.000,0.000,192.000,0.000,512.000
enc-attention-context,377.295,646.425,160.000,32.000,0.000,8.000,12.000,144.000
enc-attention-dense,1035.733,792.744,32.000,40.008,16.000,16.000,0.000,64.000
enc-post-attention-dropout,186.605,100.414,40.008,24.000,0.000,24.000,28.000,128.000
enc-2nd-layernorm,88.124,260.478,24.000,40.000,0.000,16.016,0.000,128.000
enc-MLP-GEMM-1,1702.803,3502.140,40.000,56.016,64.000,32.000,0.000,176.000
enc-MLP-gelu,93.683,201.279,56.016,56.000,0.000,32.000,0.000,208.000
enc-MLP-GEMM-2,2245.035,2832.726,56.000,40.008,64.000,16.000,0.000,144.000
enc-post-MLP-dropout,187.290,100.682,40.008,24.000,0.000,24.000,28.000,128.000
final-layernorm,90.128,945.655,24.000,24.000,0.000,16.016,0.000,64.000
gpt-post-process,6991.111,10121.454,24.000,8.000,200.000,200.025,99.975,0.000
